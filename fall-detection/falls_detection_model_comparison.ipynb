{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'matlab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6d854e149955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# import packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mmatlab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'matlab'"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import scipy.io as sio\n",
    "import matlab.engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matlab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5ecbe43db66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# run matlab script to put data together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatlab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect_matlab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0meng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\ishparii\\dev\\SkyFall_GLM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnargout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0meng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnargout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matlab' is not defined"
     ]
    }
   ],
   "source": [
    "# run matlab script to put data together\n",
    "eng = matlab.engine.connect_matlab()\n",
    "eng.cd(r'C:\\Users\\ishparii\\dev\\SkyFall_GLM', nargout=0)\n",
    "eng.ls(nargout=0)\n",
    "\n",
    "data_CF = eng.TrainingDataSetup([],[],10,0) #location -use all; subjID - use all; n jitter - 10; condition - healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_CF_np = np.array(data_CF)\n",
    "data_CF_df = pd.DataFrame(data_CF_np)\n",
    "\n",
    "print(data_CF_df.shape)\n",
    "data_CF_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# location: 0 - N/A; 1 - pouch; 2 - pocket; 3 - hand\n",
    "# subj_code: 0 - amputee; 1 - healthy\n",
    "# label: 1 - slip; 2 - trip; 3 - right; 4 - left\n",
    "data_CF_df=data_CF_df.rename(columns = {0:'subj_id', 1:'location', 2:'subj_code', 3:'label'})\n",
    "\n",
    "# save data to file\n",
    "data_CF_df.to_csv('data_CF.csv')\n",
    "\n",
    "data_CF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_AF = eng.TrainingDataSetup([],[],10,1) #location -use all; subjID - use all; n jitter - 10; condition - amputees\n",
    "# data_AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_AF_np = np.array(data_AF)\n",
    "data_AF_df = pd.DataFrame(data_AF_np)\n",
    "\n",
    "print(data_AF_df.shape)\n",
    "data_AF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# location: 0 - N/A; 1 - pouch; 2 - pocket; 3 - hand\n",
    "# subj_code: 0 - amputee; 1 - healthy\n",
    "# label: 1 - slip; 2 - trip; 3 - right; 4 - left\n",
    "data_AF_df=data_AF_df.rename(columns = {0:'subj_id', 1:'location', 2:'subj_code', 3:'label'})\n",
    "\n",
    "# save data to file\n",
    "data_AF_df.to_csv('data_AF.csv')\n",
    "\n",
    "data_AF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read data from csv files\n",
    "data_CF_df = pd.read_csv('data_CF.csv', index_col=0)\n",
    "data_CF_df.head()\n",
    "\n",
    "data_AF_df = pd.read_csv('data_AF.csv', index_col=0)\n",
    "data_AF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# changing labels: 1 - fall; 9 - non-fall \n",
    "data_CF_df.loc[(data_CF_df.label == 4) | (data_CF_df.label == 3) | (data_CF_df.label == 2), ['label']] = 1\n",
    "data_AF_df.loc[(data_AF_df.label == 4) | (data_AF_df.label == 3) | (data_AF_df.label == 2), ['label']] = 1\n",
    "\n",
    "# change amputee subjects ids\n",
    "max_id_CF = data_CF_df.subj_id.max()\n",
    "print(max_id_CF)\n",
    "data_AF_df.subj_id = data_AF_df.subj_id + max_id_CF\n",
    "print(\"Amputee subjects id: \", data_AF_df.subj_id.unique())\n",
    "print()\n",
    "print(\"Unique labels: \", data_AF_df.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training and testing data split\n",
    "\n",
    "# location: 0 - N/A; 1 - pouch; 2 - pocket; 3 - hand\n",
    "# subj_code: 0 - amputee; 1 - healthy\n",
    "# label: 1 - slip; 2 - trip; 3 - right; 4 - left\n",
    "data_train = data_CF_df.loc[data_CF_df['location'] == 2] # pocket data\n",
    "data_test = data_AF_df.loc[data_AF_df['location'] == 2]\n",
    "\n",
    "#data_train = data_CF_df[(data_CF_df.location == 1) & ((data_CF_df.label>0) & (data_CF_df.label<=4))]\n",
    "#data_test = data_AF_df[(data_AF_df.location == 1) & ((data_AF_df.label>0) & (data_AF_df.label<=4))]\n",
    "\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mix data\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = data_CF_df\n",
    "full_data = data.append(data_AF_df)\n",
    "\n",
    "# location: 0 - N/A; 1 - pouch; 2 - pocket; 3 - hand\n",
    "# subj_code: 0 - amputee; 1 - healthy\n",
    "# label: 1 - slip; 2 - trip; 3 - right; 4 - left\n",
    "# full_data = full_data[((full_data.location == 1) \n",
    "# #                        | (full_data.location == 3)\n",
    "#                       )] # data for pouch + hand\n",
    "print(\"Data size: \", full_data.shape)\n",
    "print()\n",
    "\n",
    "subj_ids = np.sort(np.array(full_data.subj_id.unique()))\n",
    "print(\"All subjects ids: \",subj_ids)\n",
    "\n",
    "# first and last 2 subjects ids for testing\n",
    "test_subjects = subj_ids[np.r_[0:2, -2:0]]\n",
    "print(\"Subjects for testing: \",test_subjects)\n",
    "\n",
    "train_subjects = np.setdiff1d(subj_ids,test_subjects)\n",
    "print(\"Subjects for training: \",train_subjects)\n",
    "\n",
    "data_train = full_data.loc[full_data['subj_id'].isin(train_subjects)]\n",
    "data_test = full_data.loc[full_data['subj_id'].isin(test_subjects)]\n",
    "# group data by subject\n",
    "#groups = full_data.groupby('subj_id')\n",
    "#groups.head()\n",
    "\n",
    "#random.shuffle(groups)\n",
    "\n",
    "#for g, grp in groups:\n",
    "#    print (grp)\n",
    "\n",
    "#data = pd.DataFrame(groups)\n",
    "#print(data.shape)\n",
    "#data.head()\n",
    "\n",
    "#data_train, data_test = train_test_split(data, test_size=0.3)\n",
    "print(\"Training data size: \", data_train.shape)\n",
    "print(\"Testing data size: \",data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Unique labels in training set: \", data_train.label.unique())\n",
    "print()\n",
    "print(\"Unique labels in testing set: \", data_test.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of features\n",
    "features = list(range(4,1215))\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# handpicking features\n",
    "\n",
    "# feature groups:\n",
    "#       1 - Raw Signal Statistics\n",
    "#       2 - Raw Signal Correlation Coefficients\n",
    "#       3 - Raw Signal 5s FFT bins\n",
    "#       4 - Raw Signal 1s FFT bins\n",
    "#\t\t5 - Derivative Statistics\n",
    "#\t\t6 - Derivative 5s FFT bins\n",
    "#\t\t7 - Derivative 1s FFT bins\n",
    "#\t\t8 - Resultant Vector and Magnitude \n",
    "#\t\t9 - Angle Statistics (ArcTan)\n",
    "#\t\t10 - Entropies\n",
    "#\t\t11 - Raw Signal Cross Products\n",
    "#\t\t12 - Derivative Cross Products\n",
    "#\t\t13 - Raw Signal Statistics on 1s FFT bins\n",
    "#\t\t14 - Raw Signal Entropies on 1s FFT bins\n",
    "#\t\t15 - Raw Signal Statistics on 1s binned signal energy\n",
    "#\t\t16 - Derivative Statistics on 1s FFT bins\n",
    "#\t\t17 - Derivative Entropies on 1s FFT bins\n",
    "#\t\t18 - Barometer\n",
    "\n",
    "features_to_use = eng.getFeatureInds(matlab.logical([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]))\n",
    "\n",
    "features_to_use = np.array(features_to_use)\n",
    "features_to_use = [y for x in features_to_use for y in x] # flatten array\n",
    "features_to_use = np.array(features_to_use)\n",
    "\n",
    "features = features[features_to_use]\n",
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features analysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "X = data_train[features]\n",
    "Y = data_train['label']\n",
    "\n",
    "forest.fit(X, Y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize feature importances\n",
    "\n",
    "importances = np.array(importances)\n",
    "importances /= importances.max()\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select features > 10 % importance\n",
    "features = [i for i,j in zip(features,importances) if j > 0.1]\n",
    "\n",
    "print (\"Selected number of features: %d\" % len(features))\n",
    "\n",
    "for f in range(len(features)):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn import metrics, svm, neighbors, linear_model, tree\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting data for training\n",
    "X = data_train[features] # data for training\n",
    "Y = data_train['label'] # target labels\n",
    "groups = data_train['subj_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different models to try\n",
    "#       Model name ---------------------------------------------------------------------\n",
    "#      Parameters ------------------------------------------                           |\n",
    "#     Classifier -----------                               |                           |\n",
    "#                          |                               |                           |\n",
    "#                          v                               v                           |\n",
    "models = [#[tree.DecisionTreeClassifier(), {'min_samples_split': [2, 4, 6, 8, 10],#    |\n",
    "#                                            'min_samples_leaf': [1, 5, 10, 15, 20],#     v\n",
    "#                                            'max_depth': [10, 20, 30, 40, 50]},       \"Decision Tree\"]\n",
    "          ]\n",
    "\n",
    "# models.append([linear_model.LogisticRegression(), {'C': [1e+4, 1e+3, 1e+2, 1e+1, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]}, \"Logistic Regression with Ridge Penalty\"])\n",
    "\n",
    "# models.append([linear_model.LogisticRegression(penalty='l1'), {'C': [100, 10, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]}, \"Logistic Regression with Lasso Penalty\"])\n",
    "\n",
    "# LinearSVC\n",
    "#models.append([svm.SVC(kernel='rbf', class_weight={1:10,9:1}), {#'kernel': ['rbf'], # class_weight=\"balanced\"; tol\n",
    "                          # 'gamma': [1e+4, 1e+3, 1e+2, 1e+1, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6], \n",
    "                           #'C': [1e+4, 1e+3, 1e+2, 1e+1, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]}, \"SVM rbf\"])\n",
    "\n",
    "# models.append([neighbors.KNeighborsClassifier(), {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15]}, \"K-Nearest Neighbors\"])\n",
    "\n",
    "\n",
    "\n",
    "models.append([RandomForestClassifier(), {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200],\n",
    "                                           'max_depth': [1, 10, 20, 30, 40, 50],\n",
    "                                           'min_samples_leaf': [1, 5, 10, 15, 20],\n",
    "                                          'min_samples_split': [2, 4, 6, 8, 10]\n",
    "                                           }, \"Random Forest\"])\n",
    "\n",
    "models_with_best_params = []\n",
    "\n",
    "# cross-validation strategy\n",
    "# cv = 10 # for 10-folds cross-validation\n",
    "\n",
    "# Leave One Group Out\n",
    "logo = LeaveOneGroupOut()\n",
    "cv = logo.get_n_splits(X,Y,groups)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    clf = GridSearchCV(model[0], model[1], cv=cv)\n",
    "    clf.fit(X, Y)\n",
    "    best_params = clf.best_params_\n",
    "    best_estimator = clf.best_estimator_\n",
    "    \n",
    "    model_with_best_params = [best_estimator, best_params, model[2]]\n",
    "    \n",
    "    models_with_best_params.append(model_with_best_params)\n",
    "    \n",
    "    print(model[2], \": \")\n",
    "    print(\"Best score for \", model[2], \":\", clf.best_score_)\n",
    "    print()\n",
    "    print(\"Best parameters for \", model[2], \" found on development set:\", best_params)\n",
    "    print()\n",
    "    print(\"Best estimator for \", model[2], \" model:\", best_estimator)\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "print(models_with_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fitting models to test_data\n",
    "for model in models_with_best_params:\n",
    "    classifier = model[0]\n",
    "    classifier.fit(X, Y)\n",
    "    score = classifier.score(data_test[features], data_test['label'])\n",
    "    print(\"Prediction accuracy for\", model[2], \"model is\", score)\n",
    "    expected = data_test['label']\n",
    "    predicted = classifier.predict(data_test[features])\n",
    "\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted, digits=5)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count falls and non-falls in test set\n",
    "labels_np = np.array(expected)\n",
    "unique, counts = np.unique(labels_np, return_counts=True)\n",
    "\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
